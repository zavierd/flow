"""
æ™ºèƒ½å±æ€§æ˜ å°„å™¨
è´Ÿè´£å°†AIåˆ†æçš„å±æ€§ç»“æœæ˜ å°„åˆ°æ•°æ®åº“æ¨¡å‹
"""

import logging
from typing import Dict, Any, List, Optional
from django.db import transaction
from products.models import Attribute, AttributeValue, SKU, SPU, SKUAttributeValue, SPUAttribute

logger = logging.getLogger(__name__)


class SmartAttributeMapper:
    """æ™ºèƒ½å±æ€§æ˜ å°„å™¨ - å°†AIåˆ†æç»“æœæ˜ å°„åˆ°æ•°æ®åº“"""
    
    def __init__(self):
        self.created_attributes = {}  # ç¼“å­˜å·²åˆ›å»ºçš„å±æ€§
        self.created_values = {}      # ç¼“å­˜å·²åˆ›å»ºçš„å±æ€§å€¼
        
    def map_attributes_to_sku(self, sku: SKU, spu: SPU, analyzed_attributes: List[Dict[str, Any]]) -> int:
        """å°†åˆ†æçš„å±æ€§æ˜ å°„åˆ°SKU"""
        mapped_count = 0
        
        with transaction.atomic():
            for attr_analysis in analyzed_attributes:
                try:
                    success = self._create_attribute_mapping(sku, spu, attr_analysis)
                    if success:
                        mapped_count += 1
                        logger.debug(f"ğŸ”— æ˜ å°„å±æ€§: {attr_analysis['display_name']} = {attr_analysis['display_value']}")
                    
                except Exception as e:
                    logger.warning(f"æ˜ å°„å±æ€§å¤±è´¥ {attr_analysis.get('display_name', 'unknown')}: {str(e)}")
        
        return mapped_count
    
    def _create_attribute_mapping(self, sku: SKU, spu: SPU, attr_analysis: Dict[str, Any]) -> bool:
        """åˆ›å»ºå•ä¸ªå±æ€§æ˜ å°„"""
        try:
            # 1. åˆ›å»ºæˆ–è·å–å±æ€§å®šä¹‰
            attribute = self._get_or_create_attribute(attr_analysis)
            if not attribute:
                return False
            
            # 2. åˆ›å»ºæˆ–è·å–å±æ€§å€¼
            attribute_value = self._get_or_create_attribute_value(attribute, attr_analysis)
            if not attribute_value:
                return False
            
            # 3. åˆ›å»ºSKUå±æ€§å€¼å…³è”
            sku_attr_value, created = SKUAttributeValue.objects.get_or_create(
                sku=sku,
                attribute=attribute,
                defaults={'attribute_value': attribute_value}
            )
            
            # å¦‚æœå·²å­˜åœ¨ä½†å€¼ä¸åŒï¼Œæ›´æ–°å±æ€§å€¼
            if not created and sku_attr_value.attribute_value != attribute_value:
                sku_attr_value.attribute_value = attribute_value
                sku_attr_value.save()
                logger.debug(f"ğŸ“ æ›´æ–°SKUå±æ€§å€¼: {attribute.name} = {attribute_value.value}")
            
            # 4. åˆ›å»ºSPUå±æ€§å…³è”
            spu_attribute, created = SPUAttribute.objects.get_or_create(
                spu=spu,
                attribute=attribute,
                defaults={
                    'is_required': False,
                    'order': self._calculate_attribute_order(attr_analysis)
                }
            )
            
            return True
            
        except Exception as e:
            logger.error(f"åˆ›å»ºå±æ€§æ˜ å°„å¤±è´¥: {str(e)}")
            return False
    
    def _get_or_create_attribute(self, attr_analysis: Dict[str, Any]) -> Optional[Attribute]:
        """è·å–æˆ–åˆ›å»ºå±æ€§å®šä¹‰"""
        try:
            display_name = attr_analysis['display_name']
            attr_type = attr_analysis['attribute_type']
            filterable = attr_analysis.get('filterable', False)
            
            # ç”Ÿæˆå±æ€§ç¼–ç 
            attr_code = self._generate_attribute_code(display_name)
            
            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"{attr_code}_{attr_type}"
            if cache_key in self.created_attributes:
                return self.created_attributes[cache_key]
            
            # åˆ›å»ºæˆ–è·å–å±æ€§
            attribute, created = Attribute.objects.get_or_create(
                code=attr_code,
                defaults={
                    'name': display_name,
                    'type': attr_type,
                    'is_required': False,
                    'is_filterable': filterable,
                    'description': f'AIæ™ºèƒ½è¯†åˆ«çš„å±æ€§ (ç½®ä¿¡åº¦: {attr_analysis.get("confidence", 0):.2f})'
                }
            )
            
            if created:
                logger.info(f"âœ¨ AIåˆ›å»ºæ–°å±æ€§: {display_name} ({attr_type})")
            
            # æ›´æ–°ç°æœ‰å±æ€§çš„å¯ç­›é€‰æ€§ï¼ˆå¦‚æœAIå»ºè®®æ›´æ”¹ï¼‰
            elif not attribute.is_filterable and filterable:
                attribute.is_filterable = True
                attribute.save()
                logger.info(f"ğŸ“ æ›´æ–°å±æ€§å¯ç­›é€‰æ€§: {display_name}")
            
            # ç¼“å­˜å±æ€§
            self.created_attributes[cache_key] = attribute
            return attribute
            
        except Exception as e:
            logger.error(f"åˆ›å»ºå±æ€§å®šä¹‰å¤±è´¥: {str(e)}")
            return None
    
    def _get_or_create_attribute_value(self, attribute: Attribute, attr_analysis: Dict[str, Any]) -> Optional[AttributeValue]:
        """è·å–æˆ–åˆ›å»ºå±æ€§å€¼"""
        try:
            display_value = attr_analysis['display_value']
            
            # æ£€æŸ¥ç¼“å­˜
            cache_key = f"{attribute.id}_{display_value}"
            if cache_key in self.created_values:
                return self.created_values[cache_key]
            
            # åˆ›å»ºæˆ–è·å–å±æ€§å€¼
            attribute_value, created = AttributeValue.objects.get_or_create(
                attribute=attribute,
                value=display_value,
                defaults={
                    'display_name': display_value,
                    'description': f'AIæ™ºèƒ½è¯†åˆ«çš„å±æ€§å€¼'
                }
            )
            
            if created:
                logger.debug(f"âœ¨ åˆ›å»ºæ–°å±æ€§å€¼: {attribute.name} = {display_value}")
            
            # ç¼“å­˜å±æ€§å€¼
            self.created_values[cache_key] = attribute_value
            return attribute_value
            
        except Exception as e:
            logger.error(f"åˆ›å»ºå±æ€§å€¼å¤±è´¥: {str(e)}")
            return None
    
    def _generate_attribute_code(self, display_name: str) -> str:
        """ç”Ÿæˆå±æ€§ç¼–ç """
        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œè½¬æ¢ä¸ºå¤§å†™
        import re
        code = re.sub(r'[^\w\s]', '', display_name)
        code = re.sub(r'\s+', '_', code.strip())
        code = code.upper()
        
        # å¦‚æœç¼–ç ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤å‰ç¼€
        if not code:
            code = 'ATTR'
        
        # é™åˆ¶é•¿åº¦
        if len(code) > 50:
            code = code[:50]
        
        return code
    
    def _calculate_attribute_order(self, attr_analysis: Dict[str, Any]) -> int:
        """è®¡ç®—å±æ€§æ˜¾ç¤ºé¡ºåº"""
        importance = attr_analysis.get('importance', 3)
        
        # é‡è¦ç¨‹åº¦è¶Šé«˜ï¼Œæ’åºè¶Šé å‰
        # åŸºç¡€æ’åºä»100å¼€å§‹ï¼Œä¸ºé¢„å®šä¹‰å±æ€§ç•™å‡ºç©ºé—´
        base_order = 100
        
        # é‡è¦ç¨‹åº¦5: 100-109
        # é‡è¦ç¨‹åº¦4: 110-119
        # é‡è¦ç¨‹åº¦3: 120-129
        # é‡è¦ç¨‹åº¦2: 130-139
        # é‡è¦ç¨‹åº¦1: 140-149
        order_range_start = base_order + (5 - importance) * 10
        
        # åœ¨èŒƒå›´å†…éšæœºåˆ†é…ï¼Œé¿å…å†²çª
        import random
        return order_range_start + random.randint(0, 9)
    
    def get_mapping_statistics(self) -> Dict[str, Any]:
        """è·å–æ˜ å°„ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'created_attributes_count': len(self.created_attributes),
            'created_values_count': len(self.created_values),
            'attribute_types': self._get_attribute_type_distribution(),
            'filterable_attributes': self._count_filterable_attributes()
        }
    
    def _get_attribute_type_distribution(self) -> Dict[str, int]:
        """è·å–å±æ€§ç±»å‹åˆ†å¸ƒ"""
        type_counts = {}
        for attribute in self.created_attributes.values():
            attr_type = attribute.type
            type_counts[attr_type] = type_counts.get(attr_type, 0) + 1
        return type_counts
    
    def _count_filterable_attributes(self) -> int:
        """ç»Ÿè®¡å¯ç­›é€‰å±æ€§æ•°é‡"""
        return sum(1 for attr in self.created_attributes.values() if attr.is_filterable)
    
    def clear_cache(self):
        """æ¸…ç©ºç¼“å­˜"""
        self.created_attributes.clear()
        self.created_values.clear()
        logger.debug("ğŸ§¹ æ¸…ç©ºå±æ€§æ˜ å°„ç¼“å­˜")
    
    def batch_optimize_attributes(self, analyzed_attributes: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æ‰¹é‡ä¼˜åŒ–å±æ€§ï¼ˆåˆå¹¶ç›¸ä¼¼å±æ€§ã€æ ‡å‡†åŒ–ç­‰ï¼‰"""
        optimization_result = {
            'merged_attributes': 0,
            'standardized_values': 0,
            'suggestions': []
        }
        
        # æŸ¥æ‰¾ç›¸ä¼¼å±æ€§
        similar_groups = self._find_similar_attributes(analyzed_attributes)
        
        for group in similar_groups:
            if len(group) > 1:
                # å»ºè®®åˆå¹¶ç›¸ä¼¼å±æ€§
                primary_attr = max(group, key=lambda x: x.get('confidence', 0))
                optimization_result['suggestions'].append({
                    'type': 'merge_attributes',
                    'primary': primary_attr['display_name'],
                    'similar': [attr['display_name'] for attr in group if attr != primary_attr],
                    'confidence': primary_attr.get('confidence', 0)
                })
        
        return optimization_result
    
    def _find_similar_attributes(self, analyzed_attributes: List[Dict[str, Any]]) -> List[List[Dict[str, Any]]]:
        """æŸ¥æ‰¾ç›¸ä¼¼çš„å±æ€§"""
        # ç®€å•çš„ç›¸ä¼¼æ€§æ£€æµ‹ï¼ˆåŸºäºåç§°ç›¸ä¼¼åº¦ï¼‰
        similar_groups = []
        processed = set()
        
        for i, attr1 in enumerate(analyzed_attributes):
            if i in processed:
                continue
            
            group = [attr1]
            processed.add(i)
            
            for j, attr2 in enumerate(analyzed_attributes[i+1:], i+1):
                if j in processed:
                    continue
                
                # æ£€æŸ¥åç§°ç›¸ä¼¼æ€§
                if self._are_attributes_similar(attr1, attr2):
                    group.append(attr2)
                    processed.add(j)
            
            if len(group) > 1:
                similar_groups.append(group)
        
        return similar_groups
    
    def _are_attributes_similar(self, attr1: Dict[str, Any], attr2: Dict[str, Any]) -> bool:
        """åˆ¤æ–­ä¸¤ä¸ªå±æ€§æ˜¯å¦ç›¸ä¼¼"""
        name1 = attr1['display_name'].lower()
        name2 = attr2['display_name'].lower()
        
        # ç®€å•çš„ç›¸ä¼¼æ€§æ£€æµ‹
        if name1 == name2:
            return True
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç›¸åŒçš„å…³é”®è¯
        keywords1 = set(name1.split())
        keywords2 = set(name2.split())
        
        # å¦‚æœæœ‰è¶…è¿‡50%çš„å…³é”®è¯é‡å ï¼Œè®¤ä¸ºç›¸ä¼¼
        if keywords1 and keywords2:
            overlap = len(keywords1.intersection(keywords2))
            total = len(keywords1.union(keywords2))
            similarity = overlap / total
            return similarity > 0.5
        
        return False
